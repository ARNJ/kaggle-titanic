{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport re as re",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d922901c48f1849910fba05ba8f4ffc6f29bc60f"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv',  dtype={'Age': np.float64})\ntest  = pd.read_csv('../input/test.csv' ,  dtype={'Age': np.float64})\nfull_data = [train, test]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c090814b81dcf7147fc46bf7c17967ac54c0809f"
      },
      "cell_type": "code",
      "source": "print(type(train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b4770f1f7d5910edb1909d9be8c6ba92b579528"
      },
      "cell_type": "code",
      "source": "train.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6edbb229c58fcf5eb9471bc6e7a2dfff8d445802"
      },
      "cell_type": "code",
      "source": "print(train.info())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf7e068445b18ef261933dda775faf4aa585dee7"
      },
      "cell_type": "markdown",
      "source": "### Feature Engineering"
    },
    {
      "metadata": {
        "_uuid": "f00c9fb4ac4c920f0dc35c83613d17b75b597a5d"
      },
      "cell_type": "markdown",
      "source": "1. Pclass\nfrom above we knew : it is a numerical value and no missing value in this feature."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e485deed57d0930bb98994292a752907b43d40a4"
      },
      "cell_type": "code",
      "source": "print(train[['Pclass','Survived']].groupby(['Pclass'], as_index = False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "affa99c698ffcbfc86203a3ffd359aa0af7554f6"
      },
      "cell_type": "markdown",
      "source": "2. Sex"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34bbf2470e000d0615e33ebed4592945cb11dd68"
      },
      "cell_type": "code",
      "source": "print(train[['Sex','Survived']].groupby(['Sex'], as_index = False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2fc398ac4efe9eafe93f0ebb2ce719994dde5259"
      },
      "cell_type": "markdown",
      "source": "3. SibSp and Parch\nWith the number of siblings/spouse and the number of childre/parents\nwe can create new feature called family size"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "17ae7c5ba5bb4cebec8b92db52ac007b2a1e65f9"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    dataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1\nprint(train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4f5c011ba3eea212318eda4a967a4a219eeff30d"
      },
      "cell_type": "markdown",
      "source": "it seems has a good effect on our prediction but let's go further and categorize people to check whether they are alone in this ship or not.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5655bcfae347c4f9c2e9c60950f3a05918064d11"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize']==1, 'IsAlone'] = 1\nprint(train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index = False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "15119d0bd84b69e74d488df415a24f43cf82e35d"
      },
      "cell_type": "markdown",
      "source": "4. Embared\nthis feature has some mising value, thus, we will fill those with most occurred value ( 'S' )."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72b1703e04df9675452e21fcbe2d484b51a5f0a0"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f0203e214d1829032afe4cc8e812f8f1b40cf6af"
      },
      "cell_type": "markdown",
      "source": "5. Fare\nFare also has missing value and we will replace it with median, then we categorize it into 4 ranges"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e9f33e7ab0199ae762dae4de1069ab172a92602"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0937dc77bff7202d4ce119708f7c843cd7ed423d"
      },
      "cell_type": "markdown",
      "source": "6. Age\nwe have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std). then we categorize age into 5 range."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3c99d090cb832cdc78980a5cc7e730bfcb4c514"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    age_avg  = dataset['Age'].mean()\n    age_std   = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d570a703afe73d2ff2d20cfa3b640f89abba06ee"
      },
      "cell_type": "markdown",
      "source": "7. Name\ninside this feature we can find the title of people."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b84a3721d573b869b2bea811cf1bfdc23bb12d0"
      },
      "cell_type": "code",
      "source": "def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\nprint(pd.crosstab(train['Title'], train['Sex']))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "17264f50613660281754e456efc1876f924e3a14"
      },
      "cell_type": "markdown",
      "source": "so we have titles. let's categorize it and check the title impact on survival rate.\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc4ca3410e9a64e1a72ded4a29fa928672b2b20f"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nprint (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ac59b1ddb02246c26cd9887ea29b1e8f5ce13e0"
      },
      "cell_type": "markdown",
      "source": "### Data Cleaning\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6410c45b25820c16c98c2ebe8362a991504df13d"
      },
      "cell_type": "code",
      "source": "print(type(train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31ee10e6cd939d76a9b94ff6a7500fe774944f6e"
      },
      "cell_type": "code",
      "source": "for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(str).astype(int)\n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)   \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare']  = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age']   = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']  = 4\n\n# Feature Selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n                 'Parch', 'FamilySize']\n\ntrain = train.drop(['Cabin', 'SibSp', 'Parch','FamilySize'], axis = 1)\ntrain = train.drop(['PassengerId', 'Name', 'Ticket'], axis = 1)\n#train = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n\ntrain = train.values\ntest  = test.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "db632688954bdd8d0716b906de075c939c226214"
      },
      "cell_type": "markdown",
      "source": "### Classifier Comparis\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e7bcf3512b5d51a6916a251250f2b9b59564d42"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e3a92696b3cac61ed49bc6f5f75ac598820e896"
      },
      "cell_type": "code",
      "source": "classifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog  = pd.DataFrame(columns=log_cols)\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\nX = train[0::, 1::]\ny = train[0::, 0]\n\nacc_dict = {}\n\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    for clf in classifiers:\n        name = clf.__class__.__name__\n        clf.fit(X_train, y_train)\n        train_predictions = clf.predict(X_test)\n        acc = accuracy_score(y_test, train_predictions)\n\n        if name in acc_dict:\n            acc_dict[name] += acc\n        else:\n            acc_dict[name] = acc\n\nfor clf in acc_dict:\n    acc_dict[clf] = acc_dict[clf] / 10.0\n    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n    log = log.append(log_entry)\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "06f51747039baf5b8c9a36184adcc49f59a27f34"
      },
      "cell_type": "markdown",
      "source": "### Prediction\nnow we can use SVC classifier to predict our data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "853ec55b4edbdbf8c6d52ba10e75776a09b9c150"
      },
      "cell_type": "code",
      "source": "candidate_classifier = SVC()\ncandidate_classifier.fit(train[0::, 1::], train[0::, 0])\nresult = candidate_classifier.predict(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0921b0a895865fcefefbd1599b38df05b42c1d1f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}